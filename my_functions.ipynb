{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dbc14b9",
   "metadata": {},
   "source": [
    "Function to transform the raw data as explained in the preprocessing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb54b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_origin(X):\n",
    "    \n",
    "    x0 = X['x0'].copy()\n",
    "    y0 = X['y0'].copy()\n",
    "    counter = 0\n",
    "    \n",
    "    for column in X.columns:\n",
    "        \n",
    "        if counter%2 == 0:\n",
    "            X.loc[:,column] -= x0 #loc is faster, it computes the whole column at once instead of one row at a time\n",
    "        else:\n",
    "            X.loc[:,column] -= y0\n",
    "        counter +=  1\n",
    "\n",
    "    return X\n",
    "\n",
    "def separate_x_y(pos):\n",
    "    \n",
    "    x = [] \n",
    "    y = [] \n",
    "    counter =0\n",
    "    \n",
    "    for i in pos:\n",
    "        if counter%2==0:\n",
    "            x.append(i)\n",
    "        else: y.append(i)\n",
    "        counter += 1\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "def normalize_pos(pos):\n",
    "    \n",
    "    x_coords_list, y_coords_list = separate_x_y(pos)\n",
    "    max_x = max(x_coords_list)\n",
    "    min_x = min(x_coords_list)\n",
    "    max_y = max(y_coords_list)\n",
    "    min_y = min(y_coords_list)\n",
    "    \n",
    "    for i in range(len(pos)):\n",
    "        if i%2==0:\n",
    "            pos[i] = (pos[i]- min_x)/(max_x-min_x)\n",
    "        else:\n",
    "            pos[i] = (pos[i]- min_y)/(max_y-min_y)    \n",
    "        \n",
    "    return pos\n",
    "\n",
    "def normalize_dataset(X):\n",
    "    \n",
    "    X_normalized = X.copy()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_normalized.iloc[i] = normalize_pos(X.iloc[i])\n",
    "        \n",
    "    return X_normalized\n",
    "\n",
    "def transform_fn(raw_X_df):\n",
    "    X_normalized = normalize_dataset(raw_X_df).copy()\n",
    "    X_normalized_and_centered = change_origin(X_normalized).copy()\n",
    "    transformed_X_df = X_normalized_and_centered.iloc[:, 2:].copy()\n",
    "    return transformed_X_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638f898",
   "metadata": {},
   "source": [
    "Hand Detector Object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26944596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import nbconvert\n",
    "\n",
    "class hand_detector():\n",
    "    def __init__(self, static=False, n_maxhands=1, detectionCon=0.5, trackingCon=0.5):\n",
    "        self.mode = static\n",
    "        self.n_maxhands = n_maxhands\n",
    "        self.detectkionCon = detectionCon\n",
    "        self.trackingCon = trackingCon\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.n_maxhands, self.detectkionCon, self.trackingCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        \n",
    "    def find_hands(self, img, draw=True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        self.results = self.hands.process(imgRGB) #The model processes the img, results has all the information, ALL. \n",
    "        #print(self.results.multi_hand_landmarks) #multi hand landmarks have the coordenates of all the nodes that define a hand for the model. \n",
    "        if self.results.multi_hand_landmarks and draw:\n",
    "            for handLms in self.results.multi_hand_landmarks: #for each hand\n",
    "                self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS) #this is a single hand. We dont want it to write it in the RGB image, bc the img that we are \n",
    "                #displaying is img not imgRGB\n",
    "                ##now we want to draw the line that  connects all those dots for each hand\n",
    "\n",
    "        return img\n",
    "    def find_postion(self, img, handNo=0, draw=True ):\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            hand = self.results.multi_hand_landmarks[handNo]\n",
    "            lmList = []\n",
    "            h, w, c = img.shape #height, width and channels of img\n",
    "            for id_,lm in enumerate(hand.landmark):\n",
    "                #the coordenates are scaled, [0,1] not in pixels, to transform to pixels\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                lmList.append([id_, cx, cy])\n",
    "                #if id_ == 0:\n",
    "                #cv2.circle(img, (cx, cy), 15,(255,0,255), cv2.FILLED )\n",
    "            return lmList\n",
    "        else: return 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbb007d",
   "metadata": {},
   "source": [
    "Function that runs the Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5058453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import nbconvert\n",
    "\n",
    "def sample(pos):\n",
    "    row = []\n",
    "    for coords in pos:\n",
    "        #print(coords)\n",
    "        row.append(coords[1])\n",
    "        row.append(coords[2])\n",
    "    return row\n",
    "\n",
    "def coords_change(row):\n",
    "\n",
    "    counter = 0\n",
    "    x0 = row[counter]\n",
    "    y0 = row[counter+1]\n",
    "    position = []\n",
    "    for i in row:\n",
    "    \n",
    "        if counter%2 == 0:\n",
    "            i = i - x0\n",
    "            position.append(i)\n",
    "        else:\n",
    "            i = i - y0\n",
    "            position.append(i)\n",
    "        counter += counter + 1\n",
    "    \n",
    "    return position\n",
    "\n",
    "def main_fn(filename):\n",
    "    \n",
    "    model =  pickle.load(open(filename, 'rb'))\n",
    "\n",
    "    detector = hand_detector()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0) #opens camera for videocapture\n",
    "\n",
    "    ptime = 0\n",
    "    itime = time.time()\n",
    "    letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', \n",
    "               'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "    while True:\n",
    "        success, img =  cap.read() # this will give us our frame\n",
    "        img = cv2.flip(img,1)\n",
    "        img = detector.find_hands(img)      \n",
    "        position = detector.find_postion(img)\n",
    "        \n",
    "        if position!='None':\n",
    "            \n",
    "            result_coords =[position[0][1], position[0][2]]\n",
    "            position = sample(position)\n",
    "            position = normalize_pos(position)\n",
    "            position = coords_change(position)\n",
    "            position = np.array(position[2:]).reshape(1,-1)\n",
    "            \n",
    "            '''Prediction'''\n",
    "            y_pred = model.predict(position)\n",
    "            y_pred = letters[int(y_pred)-1]\n",
    "        else: pass\n",
    "        \n",
    "        ctime = time.time()\n",
    "        fps = 1/(ctime-ptime)\n",
    "        ptime = ctime\n",
    "        timer = ctime-itime\n",
    "        \n",
    "        cv2.putText(img, str(int(fps)), (10,40), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,1,  (255,0,255), 3)\n",
    "        cv2.putText(img, str(int(timer)), (600,40), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,1,  (255,0,255), 3)\n",
    "        if position!='None':\n",
    "            coords = (result_coords[0]-10, result_coords[1]+40)\n",
    "            cv2.putText(img, f'{y_pred}', coords, cv2.FONT_HERSHEY_SIMPLEX,1,  (255,0,255), 3)\n",
    "        cv2.imshow('Image', img) \n",
    "        cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10db403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
